{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1f5ea513-cc14-424e-8379-5258028df91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## fusión de archivos #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "404c3c4e-f646-46fe-994c-8e649a9fe9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('C:/Users/Rodrigo/OneDrive/Escritorio/UNAB/Clases_apuntes/Proyecto integradior ciencia de datos/proyecto1/dataset/train.csv')\n",
    "test_data = pd.read_csv('C:/Users/Rodrigo/OneDrive/Escritorio/UNAB/Clases_apuntes/Proyecto integradior ciencia de datos/proyecto1/dataset/test.csv')\n",
    "\n",
    "train_data['date'] = pd.to_datetime(train_data['date'])\n",
    "test_data['date'] = pd.to_datetime(test_data['date'])\n",
    "\n",
    "data = pd.concat([train_data, test_data])\n",
    "\n",
    "data = data.sort_values(by=['substation', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5b7c48dd-6323-447a-aca9-0f1cef5a211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# completar fechas y horas faltantes #####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4fcb6ee8-8043-4451-a88f-a048779cd743",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dates = pd.date_range(start=data['date'].min(), end=data['date'].max(), freq='H')\n",
    "\n",
    "complete_data = pd.DataFrame()\n",
    "\n",
    "for substation in data['substation'].unique():\n",
    "    substation_data = data[data['substation'] == substation]\n",
    "    substation_dates = pd.DataFrame(all_dates, columns=['date'])\n",
    "    substation_dates['substation'] = substation\n",
    "    substation_data = pd.merge(substation_dates, substation_data, on=['substation', 'date'], how='left')\n",
    "    complete_data = pd.concat([complete_data, substation_data])\n",
    "\n",
    "complete_data['consumption'] = complete_data.groupby('substation')['consumption'].transform(lambda x: x.interpolate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c04b6f7f-803e-44a1-b375-cb2c7a624050",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### tratamiento a outliers ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1509a49e-a292-4914-ad1c-915aa7faea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = complete_data['consumption'].quantile(0.25)\n",
    "Q3 = complete_data['consumption'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "complete_data['consumption'] = complete_data['consumption'].apply(lambda x: x if lower_bound <= x <= upper_bound else None)\n",
    "complete_data['consumption'] = complete_data.groupby('substation')['consumption'].transform(lambda x: x.interpolate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7eddd648-4ae6-4cda-bca1-24655c7214c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Normalización ######################\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ad718da9-322d-4658-93dd-9ba8d12ad0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -0.303818\n",
      "1   -0.384448\n",
      "2   -0.420303\n",
      "3   -0.482441\n",
      "4   -0.528187\n",
      "Name: consumption, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "complete_data['consumption'] = scaler.fit_transform(complete_data[['consumption']])\n",
    "\n",
    "print(complete_data['consumption'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9d12628c-584a-4aa1-b5f2-80069bba9c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\rodrigo\\anaconda3\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\rodrigo\\appdata\\roaming\\python\\python311\\site-packages (from xgboost) (1.26.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\rodrigo\\appdata\\roaming\\python\\python311\\site-packages (from xgboost) (1.14.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\rodrigo\\anaconda3\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\rodrigo\\appdata\\roaming\\python\\python311\\site-packages (from lightgbm) (1.26.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\rodrigo\\appdata\\roaming\\python\\python311\\site-packages (from lightgbm) (1.14.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "################ Entrenamiento ######################\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "!pip install xgboost\n",
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "18124bfb-4b09-41fa-86bf-f6991aa022cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = complete_data[complete_data['date'] < test_data['date'].min()]\n",
    "test_data = complete_data[complete_data['date'] >= test_data['date'].min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cb0e8e3b-2062-4f92-a5b4-9a1e668ecf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for AJAHUEL: 0.10671562006389149\n",
      "MAE for BUIN: 0.001018594141213221\n",
      "MAE for CHENA: 0.10749211116288267\n",
      "MAE for CNAVIA: 0.36017238526113676\n",
      "MAE for ELSALTO: 0.2973594944220301\n",
      "MAE for FLORIDA: 0.03139726779256665\n",
      "MAE for LOSALME: 0.14160695674007884\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "features = ['hour', 'month', 'dayofweek']\n",
    "\n",
    "complete_data['hour'] = complete_data['date'].dt.hour\n",
    "complete_data['month'] = complete_data['date'].dt.month\n",
    "complete_data['dayofweek'] = complete_data['date'].dt.dayofweek\n",
    "\n",
    "train_data = complete_data[complete_data['date'] < test_data['date'].min()]\n",
    "test_data = complete_data[complete_data['date'] >= test_data['date'].min()]\n",
    "\n",
    "X_train = train_data[features]\n",
    "y_train = train_data['consumption']\n",
    "\n",
    "models = {}\n",
    "\n",
    "for substation in train_data['substation'].unique():\n",
    "    substation_X_train = X_train[train_data['substation'] == substation]\n",
    "    substation_y_train = y_train[train_data['substation'] == substation]\n",
    "\n",
    "    X_sub_train, X_sub_val, y_sub_train, y_sub_val = train_test_split(substation_X_train, substation_y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6)\n",
    "    model.fit(X_sub_train, y_sub_train)\n",
    "\n",
    "    y_pred = model.predict(X_sub_val)\n",
    "    mae = mean_absolute_error(y_sub_val, y_pred)\n",
    "    print(f'MAE for {substation}: {mae}')\n",
    "\n",
    "    models[substation] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d16caa8d-17c4-4cab-9a90-ce4fbfd02235",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Predicciones ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "da92acad-9316-4c1e-b49f-cd5fc11c10d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "indices are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m substation \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[0;32m      5\u001b[0m     model \u001b[38;5;241m=\u001b[39m models[substation]\n\u001b[1;32m----> 6\u001b[0m     substation_X_test \u001b[38;5;241m=\u001b[39m \u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msubstation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msubstation\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      7\u001b[0m     substation_y_test \u001b[38;5;241m=\u001b[39m y_test[test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubstation\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m substation]\n\u001b[0;32m      8\u001b[0m     substation_predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(substation_X_test)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:3884\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3882\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[0;32m   3883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 3884\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_bool_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3886\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[0;32m   3887\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[0;32m   3888\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:3946\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3943\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   3945\u001b[0m indexer \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 3946\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py:4088\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   4077\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   4078\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m   4079\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4080\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   4081\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4086\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   4087\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4088\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[0;32m   4090\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py:4068\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[1;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[0;32m   4063\u001b[0m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[0;32m   4064\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[0;32m   4065\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[0;32m   4066\u001b[0m     )\n\u001b[1;32m-> 4068\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4070\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4072\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   4074\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4075\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:874\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;66;03m# Caller is responsible for ensuring indexer annotation is accurate\u001b[39;00m\n\u001b[0;32m    873\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[1;32m--> 874\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_convert_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[0;32m    878\u001b[0m     new_axis\u001b[38;5;241m=\u001b[39mnew_labels,\n\u001b[0;32m    879\u001b[0m     indexer\u001b[38;5;241m=\u001b[39mindexer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    882\u001b[0m     copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    883\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexers\\utils.py:282\u001b[0m, in \u001b[0;36mmaybe_convert_indices\u001b[1;34m(indices, n, verify)\u001b[0m\n\u001b[0;32m    280\u001b[0m     mask \u001b[38;5;241m=\u001b[39m (indices \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m n) \u001b[38;5;241m|\u001b[39m (indices \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m--> 282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indices\n",
      "\u001b[1;31mIndexError\u001b[0m: indices are out-of-bounds"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Calcular MSE y R² para cada subestación\n",
    "for substation in models:\n",
    "    model = models[substation]\n",
    "    substation_X_test = X_test[test_data['substation'] == substation]\n",
    "    substation_y_test = y_test[test_data['substation'] == substation]\n",
    "    substation_predictions = model.predict(substation_X_test)\n",
    "    \n",
    "    mse = mean_squared_error(substation_y_test, substation_predictions)\n",
    "    r2 = r2_score(substation_y_test, substation_predictions)\n",
    "    \n",
    "    print(f\"Subestación: {substation}\")\n",
    "    print(f\"MSE: {mse}\")\n",
    "    print(f\"R²: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "13777088-d054-4051-a242-777435ba1984",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## nuevo entrenamiento normalizado por subestación #####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d75ebafc-3e34-4cc6-8ab4-7e2bccb0b52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "def normalize_by_substation(substation_data):\n",
    "    substation_data['consumption'] = scaler.fit_transform(substation_data[['consumption']])\n",
    "    return substation_data\n",
    "\n",
    "complete_data = complete_data.groupby('substation').apply(normalize_by_substation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f4555059-b868-4aa8-861a-b787d8bf28c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for AJAHUEL:\n",
      "MAE: 0.10671562006389149\n",
      "MSE: 0.021334514901238805\n",
      "RMSE: 0.1460633934332583\n",
      "R²: 0.7947689574119271\n",
      "MAPE: 376.11879970267034%\n",
      "\n",
      "Metrics for BUIN:\n",
      "MAE: 0.001018594141213221\n",
      "MSE: 0.00041294218404366254\n",
      "RMSE: 0.020320978914502682\n",
      "R²: -0.0014942833030411329\n",
      "MAPE: 0.07366128676331571%\n",
      "\n",
      "Metrics for CHENA:\n",
      "MAE: 0.10749211116288267\n",
      "MSE: 0.026508272165793406\n",
      "RMSE: 0.16281361173376568\n",
      "R²: 0.7009306031018141\n",
      "MAPE: 162.91264268197193%\n",
      "\n",
      "Metrics for CNAVIA:\n",
      "MAE: 0.36017238526113676\n",
      "MSE: 0.19657174463295862\n",
      "RMSE: 0.44336412195052344\n",
      "R²: 0.5519336490849427\n",
      "MAPE: 240.6263661631184%\n",
      "\n",
      "Metrics for ELSALTO:\n",
      "MAE: 0.2973594944220301\n",
      "MSE: 0.1606678495788829\n",
      "RMSE: 0.40083394264817807\n",
      "R²: 0.7138615366272933\n",
      "MAPE: 113.52746548879516%\n",
      "\n",
      "Metrics for FLORIDA:\n",
      "MAE: 0.03139726779256665\n",
      "MSE: 0.00388341317485989\n",
      "RMSE: 0.06231703759695169\n",
      "R²: 0.2490415779869396\n",
      "MAPE: 3.0273246493977513%\n",
      "\n",
      "Metrics for LOSALME:\n",
      "MAE: 0.14160695674007884\n",
      "MSE: 0.03537645999587036\n",
      "RMSE: 0.18808630996399062\n",
      "R²: 0.6313582027079463\n",
      "MAPE: 260.3872604384838%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "models = {}\n",
    "\n",
    "for substation in train_data['substation'].unique():\n",
    "    substation_X_train = X_train[train_data['substation'] == substation]\n",
    "    substation_y_train = y_train[train_data['substation'] == substation]\n",
    "\n",
    "    X_sub_train, X_sub_val, y_sub_train, y_sub_val = train_test_split(substation_X_train, substation_y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6)\n",
    "    model.fit(X_sub_train, y_sub_train)\n",
    "\n",
    "    y_pred = model.predict(X_sub_val)\n",
    "\n",
    "    mae = mean_absolute_error(y_sub_val, y_pred)\n",
    "    mse = mean_squared_error(y_sub_val, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_sub_val, y_pred)\n",
    "    mape = np.mean(np.abs((y_sub_val - y_pred) / y_sub_val)) * 100\n",
    "\n",
    "    print(f'Metrics for {substation}:')\n",
    "    print(f'MAE: {mae}')\n",
    "    print(f'MSE: {mse}')\n",
    "    print(f'RMSE: {rmse}')\n",
    "    print(f'R²: {r2}')\n",
    "    print(f'MAPE: {mape}%\\n')\n",
    "\n",
    "    models[substation] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8c025bb8-1b17-4cbe-a66e-266e9bb9bd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      substation                date  consumption  predicted_consumption\n",
      "35064    AJAHUEL 2022-01-01 00:00:00    -0.517680              -0.131066\n",
      "35065    AJAHUEL 2022-01-01 01:00:00    -0.637328              -0.169434\n",
      "35066    AJAHUEL 2022-01-01 02:00:00    -0.681343              -0.213173\n",
      "35067    AJAHUEL 2022-01-01 03:00:00    -0.717677              -0.235776\n",
      "35068    AJAHUEL 2022-01-01 04:00:00    -0.734051              -0.255823\n"
     ]
    }
   ],
   "source": [
    "X_test = test_data[['hour', 'month', 'dayofweek']]\n",
    "y_test = test_data['consumption']\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for substation in test_data['substation'].unique():\n",
    "    substation_X_test = X_test[test_data['substation'] == substation]\n",
    "    model = models.get(substation)\n",
    "    if model:\n",
    "        substation_predictions = model.predict(substation_X_test)\n",
    "        predictions.extend(substation_predictions)\n",
    "\n",
    "predictions = np.array(predictions).reshape(-1, 1)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "test_data.loc[:, 'predicted_consumption'] = predictions\n",
    "\n",
    "print(test_data[['substation', 'date', 'consumption', 'predicted_consumption']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "67f6564f-37f5-49a3-983b-40e7579e6a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### cambio de hiperparámetros ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c4d39d58-b09b-4144-b8e5-840b663f0883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\rodrigo\\appdata\\roaming\\python\\python311\\site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\rodrigo\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\rodrigo\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\rodrigo\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\rodrigo\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\rodrigo\\anaconda3\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\rodrigo\\appdata\\roaming\\python\\python311\\site-packages (from xgboost) (1.26.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\rodrigo\\appdata\\roaming\\python\\python311\\site-packages (from xgboost) (1.14.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scikit-learn\n",
    "!pip install --upgrade xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bb289048-8cdf-4ca3-975e-06bd13ef6003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for AJAHUEL:\n",
      "MAE: 0.10628753595324142\n",
      "MSE: 0.021224660200553268\n",
      "RMSE: 0.14568685664998496\n",
      "R²: 0.7958257236360133\n",
      "MAPE: 378.2362415236959%\n",
      "\n",
      "Metrics for BUIN:\n",
      "MAE: 0.0010973938240925842\n",
      "MSE: 0.0004117644919565041\n",
      "RMSE: 0.020291980976644544\n",
      "R²: 0.001361932260190546\n",
      "MAPE: 0.08054922966968601%\n",
      "\n",
      "Metrics for CHENA:\n",
      "MAE: 0.10668760848171864\n",
      "MSE: 0.026221921305279308\n",
      "RMSE: 0.16193184154229615\n",
      "R²: 0.7041612466767558\n",
      "MAPE: 161.76133237649876%\n",
      "\n",
      "Metrics for CNAVIA:\n",
      "MAE: 0.35898347305726047\n",
      "MSE: 0.19516483689369526\n",
      "RMSE: 0.4417746449194377\n",
      "R²: 0.5551405597118131\n",
      "MAPE: 238.70331258560583%\n",
      "\n",
      "Metrics for ELSALTO:\n",
      "MAE: 0.2967522753536266\n",
      "MSE: 0.1592221749482892\n",
      "RMSE: 0.3990265341406373\n",
      "R²: 0.7164361843767917\n",
      "MAPE: 121.5668215279508%\n",
      "\n",
      "Metrics for FLORIDA:\n",
      "MAE: 0.030962903949718713\n",
      "MSE: 0.0037796821782272528\n",
      "RMSE: 0.061479119855665246\n",
      "R²: 0.2691006502611377\n",
      "MAPE: 2.985559866624595%\n",
      "\n",
      "Metrics for LOSALME:\n",
      "MAE: 0.140681442714418\n",
      "MSE: 0.03503505212626317\n",
      "RMSE: 0.1871765266433352\n",
      "R²: 0.6349158568846597\n",
      "MAPE: 236.330709257764%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8\n",
    ")\n",
    "\n",
    "models = {}\n",
    "\n",
    "for substation in train_data['substation'].unique():\n",
    "    substation_X_train = X_train[train_data['substation'] == substation]\n",
    "    substation_y_train = y_train[train_data['substation'] == substation]\n",
    "\n",
    "    X_sub_train, X_sub_val, y_sub_train, y_sub_val = train_test_split(substation_X_train, substation_y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    model.fit(X_sub_train, y_sub_train)\n",
    "\n",
    "    y_pred = model.predict(X_sub_val)\n",
    "\n",
    "    mae = mean_absolute_error(y_sub_val, y_pred)\n",
    "    mse = mean_squared_error(y_sub_val, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_sub_val, y_pred)\n",
    "    mape = np.mean(np.abs((y_sub_val - y_pred) / (y_sub_val + 1e-6))) * 100 \n",
    "    \n",
    "    print(f'Metrics for {substation}:')\n",
    "    print(f'MAE: {mae}')\n",
    "    print(f'MSE: {mse}')\n",
    "    print(f'RMSE: {rmse}')\n",
    "    print(f'R²: {r2}')\n",
    "    print(f'MAPE: {mape}%\\n')\n",
    "\n",
    "    models[substation] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a2fa9532-bc1c-4937-b8d1-447096f842ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\rodrigo\\anaconda3\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\rodrigo\\appdata\\roaming\\python\\python311\\site-packages (from lightgbm) (1.26.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\rodrigo\\appdata\\roaming\\python\\python311\\site-packages (from lightgbm) (1.14.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "################### tratamiento drástico a outliers y LightGBM ######################\n",
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45992fd-fe20-453a-8a49-635cf411c0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BUIN ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "803cfac3-7779-471c-841a-6cc1f5230218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 76\n",
      "[LightGBM] [Info] Number of data points in the train set: 35064, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score -1.145667\n",
      "\n",
      "Métricas para la subestación BUIN:\n",
      "MAE: 0.0026609995665179296\n",
      "MSE: 5.281291622114936e-05\n",
      "RMSE: 0.007267249563703545\n",
      "R²: -2.243848254636145\n",
      "MAPE: 0.23092431457522408%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_data['date'] = pd.to_datetime(train_data['date'])\n",
    "test_data['date'] = pd.to_datetime(test_data['date'])\n",
    "\n",
    "for df in [train_data, test_data]:\n",
    "    df['hour'] = df['date'].dt.hour\n",
    "    df['dayofweek'] = df['date'].dt.dayofweek\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "\n",
    "substation_name = 'BUIN'\n",
    "\n",
    "def train_and_evaluate_substation_model(substation_name):\n",
    "    substation_data_train = train_data[train_data['substation'] == substation_name]\n",
    "    substation_data_test = test_data[test_data['substation'] == substation_name]\n",
    "\n",
    "    if substation_data_train.empty or substation_data_test.empty:\n",
    "        print(f\"No hay datos para la subestación: {substation_name}\")\n",
    "        return\n",
    "\n",
    "    X_train = substation_data_train[['hour', 'dayofweek', 'month', 'day']]\n",
    "    y_train = substation_data_train['consumption']\n",
    "    X_test = substation_data_test[['hour', 'dayofweek', 'month', 'day']]\n",
    "    y_test = substation_data_test['consumption']\n",
    "\n",
    "    model = lgb.LGBMRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / (y_test + 1e-6))) * 100\n",
    "\n",
    "    print(f\"\\nMétricas para la subestación {substation_name}:\")\n",
    "    print(f'MAE: {mae}')\n",
    "    print(f'MSE: {mse}')\n",
    "    print(f'RMSE: {rmse}')\n",
    "    print(f'R²: {r2}')\n",
    "    print(f'MAPE: {mape}%')\n",
    "\n",
    "substation_name = 'BUIN'\n",
    "train_and_evaluate_substation_model(substation_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d98b4f4-10ea-4b59-99b9-5fb6716b8dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### AJAHUEL ##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e589a85d-5c9d-4dce-ab60-67ccf9decec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 648 candidates, totalling 1944 fits\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 78\n",
      "[LightGBM] [Info] Number of data points in the train set: 35064, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 1.065992\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "\n",
      "Métricas para la subestación AJAHUEL:\n",
      "MAE: 0.2866140463176125\n",
      "MSE: 0.09920638143073501\n",
      "RMSE: 0.31497044532897844\n",
      "R²: -0.7457515058696016\n",
      "MAPE: 10670.744151328747%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "substation_name = 'AJAHUEL'\n",
    "\n",
    "def train_and_evaluate_substation_model(substation_name):\n",
    "    substation_data_train = train_data[train_data['substation'] == substation_name]\n",
    "    substation_data_test = test_data[test_data['substation'] == substation_name]\n",
    "\n",
    "    if substation_data_train.empty or substation_data_test.empty:\n",
    "        print(f\"No hay datos para la subestación: {substation_name}\")\n",
    "        return\n",
    "\n",
    "    substation_data_train['generation'] = (substation_data_train['consumption'] < 0).astype(int)\n",
    "    substation_data_test['generation'] = (substation_data_test['consumption'] < 0).astype(int)\n",
    "\n",
    "    min_train_value = substation_data_train['consumption'].min()\n",
    "    if min_train_value < 0:\n",
    "        substation_data_train['consumption'] += abs(min_train_value)\n",
    "\n",
    "    min_test_value = substation_data_test['consumption'].min()\n",
    "    if min_test_value < 0:\n",
    "        substation_data_test['consumption'] += abs(min_test_value)\n",
    "\n",
    "    substation_data_train['consumption'] = np.log1p(substation_data_train['consumption'])\n",
    "    substation_data_test['consumption'] = np.log1p(substation_data_test['consumption'])\n",
    "\n",
    "    X_train = substation_data_train[['hour', 'dayofweek', 'month', 'day', 'generation']]\n",
    "    y_train = substation_data_train['consumption']\n",
    "    X_test = substation_data_test[['hour', 'dayofweek', 'month', 'day', 'generation']]\n",
    "    y_test = substation_data_test['consumption']\n",
    "\n",
    "    model = lgb.LGBMRegressor(objective='regression', metric='mae')\n",
    "\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'n_estimators': [100, 300, 500],\n",
    "        'max_depth': [5, 7, 10],\n",
    "        'num_leaves': [20, 31, 50],\n",
    "        'subsample': [0.7, 0.9],\n",
    "        'colsample_bytree': [0.7, 0.9],\n",
    "        'min_data_in_leaf': [10, 20, 30]\n",
    "    }\n",
    "\n",
    "    def custom_mape_metric(y_true, y_pred):\n",
    "        mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-6))) * 100\n",
    "        return 'mape', mape, False\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=3,\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / (y_test + 1e-6))) * 100\n",
    "\n",
    "    print(f\"\\nMétricas para la subestación {substation_name}:\")\n",
    "    print(f'MAE: {mae}')\n",
    "    print(f'MSE: {mse}')\n",
    "    print(f'RMSE: {rmse}')\n",
    "    print(f'R²: {r2}')\n",
    "    print(f'MAPE: {mape}%')\n",
    "\n",
    "train_and_evaluate_substation_model(substation_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236f2134-0ec7-4533-a5ac-3592227ce800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate_substation_model_v3(substation_name):\n",
    "    substation_data_train = train_data[train_data['substation'] == substation_name]\n",
    "    substation_data_test = test_data[test_data['substation'] == substation_name]\n",
    "\n",
    "    if substation_data_train.empty or substation_data_test.empty:\n",
    "        print(f\"No hay datos para la subestación: {substation_name}\")\n",
    "        return\n",
    "\n",
    "    substation_data_train['is_negative'] = (substation_data_train['consumption'] < 0).astype(int)\n",
    "    substation_data_test['is_negative'] = (substation_data_test['consumption'] < 0).astype(int)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    substation_data_train['consumption_scaled'] = scaler.fit_transform(substation_data_train[['consumption']])\n",
    "    substation_data_test['consumption_scaled'] = scaler.transform(substation_data_test[['consumption']])\n",
    "\n",
    "    substation_data_train['rolling_mean'] = substation_data_train['consumption_scaled'].rolling(window=3).mean().fillna(0)\n",
    "    substation_data_test['rolling_mean'] = substation_data_test['consumption_scaled'].rolling(window=3).mean().fillna(0)\n",
    "\n",
    "    X_train = substation_data_train[['hour', 'dayofweek', 'month', 'day', 'is_negative', 'rolling_mean']]\n",
    "    y_train = substation_data_train['consumption_scaled']\n",
    "    X_test = substation_data_test[['hour', 'dayofweek', 'month', 'day', 'is_negative', 'rolling_mean']]\n",
    "    y_test = substation_data_test['consumption_scaled']\n",
    "\n",
    "    model = lgb.LGBMRegressor()\n",
    "\n",
    "    param_dist = {\n",
    "        'learning_rate': [0.001, 0.01, 0.1],\n",
    "        'n_estimators': [100, 500, 1000],\n",
    "        'max_depth': [5, 10, 15],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "    }\n",
    "\n",
    "    random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=50, cv=3, scoring='neg_mean_absolute_error', verbose=1, n_jobs=-1)\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = random_search.best_estimator_\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / (y_test + 1e-6))) * 100\n",
    "\n",
    "    print(f\"\\nMétricas para la subestación {substation_name}:\")\n",
    "    print(f'MAE: {mae}')\n",
    "    print(f'MSE: {mse}')\n",
    "    print(f'RMSE: {rmse}')\n",
    "    print(f'R²: {r2}')\n",
    "    print(f'MAPE: {mape}%')\n",
    "\n",
    "train_and_evaluate_substation_model_v3(substation_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "718464e6-7936-471b-88e0-3d0be923e467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subestaciones en el conjunto de entrenamiento: ['AJAHUEL' 'BUIN' 'CHENA' 'CNAVIA' 'ELSALTO' 'FLORIDA' 'LOSALME']\n",
      "Subestaciones en el conjunto de prueba: ['AJAHUEL' 'BUIN' 'CHENA' 'CNAVIA' 'ELSALTO' 'FLORIDA' 'LOSALME']\n"
     ]
    }
   ],
   "source": [
    "print(\"Subestaciones en el conjunto de entrenamiento:\", train_data['substation'].unique())\n",
    "print(\"Subestaciones en el conjunto de prueba:\", test_data['substation'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8190954-2a26-4c38-842b-7f67ec3109bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
